<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: event-driven-architecture | Responsibly Sourced]]></title>
  <link href="http://DrewEaster.github.io/blog/categories/event-driven-architecture/atom.xml" rel="self"/>
  <link href="http://DrewEaster.github.io/"/>
  <updated>2016-06-12T11:05:09+01:00</updated>
  <id>http://DrewEaster.github.io/</id>
  <author>
    <name><![CDATA[Andrew Easter]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Practical implementation traits of service choreography based microservices integration]]></title>
    <link href="http://DrewEaster.github.io/blog/2016/06/09/practical-implementation-traits-of-service-choreography-based-microservices-integration/"/>
    <updated>2016-06-09T17:54:00+01:00</updated>
    <id>http://DrewEaster.github.io/blog/2016/06/09/practical-implementation-traits-of-service-choreography-based-microservices-integration</id>
    <content type="html"><![CDATA[<p>This is the second post in a three part series looking at the topic of microservice integration. In the <a href="http://www.dreweaster.com/blog/2016/05/08/the-art-of-microservices-integration-using-service-choreography/">first instalment</a>, I focused mainly on the theory side of event-driven service choreography. In this second part, I&rsquo;ll dig into the practical traits that we&rsquo;ll require of our technical implementations that enable us to satisfy the theory discussed in the first post. In the final instalment of the series, I&rsquo;ll look at different specific implementation techniques/technologies and how they map to the traits discussed in this post.</p>

<h2>Implementation traits</h2>

<p>I&rsquo;d like to provide some coverage on what I believe to be the key traits we look for in service choreography based microservices integration implementation techniques/technologies. My goal is to set the scene to make it easier to test specific technologies against those traits (subject of the third and final post in this series).</p>

<p>I prefer to breakdown the traits into two categories: must-haves and nice-to-haves. The must-haves category contains traits that I believe are absolutely necessary in order to successfully apply the theory of service choreography. The nice-to-haves category contains traits that you can essentially live without, but can definitely buy you additional benefits. Like with most things, though, the decision to adopt nice-to-haves will be driven by context &ndash; we&rsquo;re always making trade-offs, and you simply have to make judgement calls on a case by case basis.</p>

<p>Let&rsquo;s move on to the first category of traits, the must-haves!</p>

<h3>Must-have traits</h3>

<h4>Decoupled in time</h4>

<p>This one is pretty straightforward. In the <a href="http://www.dreweaster.com/blog/2016/05/08/the-art-of-microservices-integration-using-service-choreography/">first instalment</a> of this series, I discussed the asynchronous nature of service choreography based integration. Whatever implementation direction we go in, it needs to support us decoupling services in <em>time</em>. This means, for example, service A does not require service B to be online at a specific point in time (now) &ndash; we just need to ensure we have some mechanism in place for events from service B to eventually reach service A at some point in the future.</p>

<h4>Guaranteed at-least-once-delivery</h4>

<p>An absolute pre-requisite for ensuring eventual consistency is that we guarantee events <em>eventually</em> reach their interested consumers. But, why don&rsquo;t we aim for <em>exactly-once-delivery</em> instead? I&rsquo;m not going to repeat what many others have said before me, so suffice to say it&rsquo;s simply not possible to achieve it in a distributed system. Google is your friend if you want to explore why :&ndash;)</p>

<p>So, we&rsquo;re happy to settle for <em>at-least-once-delivery</em> because sending duplicates of a specific event is better than sending no event at all (that&rsquo;s what you might see with <em>at-most-once-delivery</em>). The ability to guarantee at-least-once-delivery also implies the need for <em>durability</em>.</p>

<p>The biggest gotcha I see when it comes to at-least-once-delivery is what I&rsquo;ve generally seen referred to as the <em>dual-write problem</em>. Whether you&rsquo;re using a traditional CRUD approach, or you&rsquo;re using eventsourcing, you are going to end up pretty unhappy if you have a unit of code that both writes to a datastore and delivers events to, say, a message queue. Let&rsquo;s examine two ways I&rsquo;ve seen this done:</p>

<h5>Write to MQ after committing a database transaction</h5>

<pre><code>doInDatabaseTransaction { statement =&gt;
  statement.insert("INSERT into ....")
}
messageQueue.publish(new SomeEvent(...))
</code></pre>

<p>Okay, so we make changes to the book of record (the database), the database transaction gets committed, and only once that happens, do we publish an event to the message queue where our interested consumers will be listening. This would work perfectly well in a world where nothing bad ever happens. But there are all sorts of things that can go wrong here, including the most obvious:</p>

<ol>
<li>Our application crashes immediately after the database transaction commits</li>
<li>Our application is restarted immediately after the database transaction commits</li>
<li>The message queue infrastructure is down for a few minutes, meaning we can&rsquo;t send the event right now</li>
</ol>


<p>In any of these cases, our book of record would be updated, but our downstream consumers would never receive the event. In one fell swoop, we&rsquo;ve guaranteed that we&rsquo;ll end up in an inconsistent state. You may say these circumstances are rare, and you&rsquo;d be right, but Murphy&rsquo;s Law &ndash; and our own experiences as software engineers &ndash; teaches us that if it can go wrong, it will go wrong. Guaranteed.</p>

<p>Let&rsquo;s try another approach&hellip;</p>

<h5>Write to MQ within scope of a database transaction</h5>

<pre><code>doInDatabaseTransaction { statement =&gt;
  statement.insert("INSERT into ....")
  messageQueue.publish(new SomeEvent(...))
}
</code></pre>

<p>Hang on, that transaction boundary is bound to the database only; it&rsquo;s got nothing to do with the message queue technology. In this example, if our database transaction were to rollback for any reason, our event would still have been published to the message queue. Oh dear, the event we sent out to interested consumers is not consistent with our book of record. Our consumers will proceed to behave as if the event has taken place, but our local context (the source of the event) will have no knowledge of it ever having taken place. That&rsquo;s bad. Very bad. Arguably even worse than the first example.</p>

<p>Let&rsquo;s get something straight here and now &ndash; unless we start dabbling in distributed transaction managers (e.g. XA standard), we can&rsquo;t atomically update a database and write to a message queue. Distributed transactions are a disease we want to quarantine ourselves from forever, so we need another way to escape from the dual-write problem. You&rsquo;ll have to wait until the third part of this mini-series for a solution ;&ndash;)</p>

<h4>Guaranteed message ordering</h4>

<p>The need for a stream of events to be consumable in order really depends on the use cases of its consumers. Very broadly speaking, there are two categories of consumer use case:</p>

<ol>
<li><p>Consumers that consume events from another service where consumption results in state transitions in the local context (e.g. projecting state locally from an external bounded context). Such consumers are conceptually <em>stateful</em> in that they care about tracking state across a series of multiple related events over time. In such cases, it&rsquo;s usually necessary to process the events in the order they were originally produced for the local state to remain consistent with the source. It&rsquo;s important to emphasise that it is only related events for which the order is necessary (e.g. events emanating from a specific aggregate instance).</p></li>
<li><p>Consumers that are conceptually <em>stateless</em> in that they can treat every event they encounter as if it&rsquo;s completely unrelated to any other event they&rsquo;ve encountered in the past. Such consumers will typically trigger some kind of one off action, such as sending an email, sending a push notification, or triggering an external API call. An example of this might be where the reaction to an event requires charging a credit card via a third-party payment gateway.</p></li>
</ol>


<p>Given that service choreography will inherently lead to many instances of use case 1) in your services, it becomes inevitable that you make implementation choices that allow events to be consumed in the order they were produced. With this in mind, it makes sense to choose implementation techniques/technologies that provide this guarantee, even if some of your consumers don&rsquo;t rely on ordering.</p>

<h4>Guaranteed at-least-once-processing</h4>

<p>Well, I guess what we really want is <em>exactly-once-processing</em>! However, I thought it would be helpful to write a separate subsection on idempotency (see below). I find it useful to separate the general action of processing from the outcome of the processing &ndash; even if we handle a message/event idempotently (e.g. through some method of deduplication), I still like to consider that the message/event has been processed, despite the absence of any side effects. I find it simpler to think of processing as meaning a consumer has handled a message/event and is now ready to handle the next one in the stream.</p>

<p>It&rsquo;s really important to emphasise the word &lsquo;eventual&rsquo; in eventual consistency. Whilst it seems obvious, I have seen people neglect the fact that eventual does mean that something will <em>definitely happen</em> in the end. Yes, we acknowledge that consistency may be delayed, but we still rely on consistency being achieved in the end. Where we&rsquo;re going down the microservices path &ndash; and following the service choreography approach &ndash; we need, in many cases, cast iron guarantees that we&rsquo;ll eventually process every event we&rsquo;re interested in. For example, if we are projecting state locally (achieving autonomy and encapsulated persistence) based on events produced by another service (bounded context), and our local business logic relies on that state, we can have zero trust in the entire system if we can&rsquo;t guarantee that we&rsquo;ll successfully process every event we&rsquo;re interested in.</p>

<p>A murky subtext here is how to deal with processing errors. Whatever the reason for an error during handling of an event, you are forced to consider the fact that, if you continue to process further events without processing the event raising the error, you could leave your system in a permanently inconsistent state. Where it&rsquo;s absolutely necessary for a consumer to handle events in order, you really are forced to block all subsequent processing until you&rsquo;ve found a way to successfully process the event that&rsquo;s raising an error. There&rsquo;s an obvious danger here that your target SLA on eventual consistency could be quickly blown out the water if, for example, the solution to the failed processing involved code changes. As discussed above, ordering is rarely a requirement across every event in a stream. With this in mind, the ability to achieve some form of parallelism in event handling may well be necessary to avoid complete gridlock in a specific consumer. I&rsquo;ll discuss this in the nice-to-haves section.</p>

<p>Where the requirement to process events in order can be relaxed, dealing with processing errors can be a little more straightforward. An option might be to log the event raising an error (after exhausting retries), and move on to subsequent events in the stream. You could put in place some mechanism to replay from the error log once necessary work has been carried out to ensure the event can be successfully processed.</p>

<p>In some circumstances, it may even be ok to never process an event. For example, consider an email notification use case. Given that processing failure rates are likely to be pretty low in normal operation, you may deem it acceptable for the odd system email to never reach an intended customer.</p>

<h4>Idempotency</h4>

<p>Given the inability to achieve exactly-once-delivery, and instead falling back to at-least-once-delivery, we can&rsquo;t just ignore the fact that consumers will, on occasion, encounter the same event more than once. Idempotency is a property of an event handler that allows the same event to be applied multiple times without any new side effects beyond the initial application. In some cases, it might be ok to live with repeated side effects, and in some cases it won&rsquo;t be ok. For example, we might not mind if we send a duplicate email, but a customer won&rsquo;t be too happy if we charge their credit card twice for the same order.</p>

<p>Some actions are naturally idempotent, in which case you don&rsquo;t need to explicitly worry about duplicate application, but there are many cases where it&rsquo;s going to matter, and so you need to introduce mechanisms to avoid duplicate application. I&rsquo;m going to resist exploring patterns for idempotent event handling in this series of posts, as it warrants dedicated coverage of its own. Mechanisms for implementing idempotency are typically application level concerns, rather than, for example, being something you can rely on some middleware layer to handle for you. Whatever implementation mechanisms you choose to integrate services via asynchronous events, you&rsquo;ll need to deal with ensuring idempotency in the way you handle the events.</p>

<p>On a side note, it&rsquo;s worth mentioning that some third-party, external services you integrate with may give you some help in this area. For example, <a href="http://www.stripe.com">Stripe&rsquo;s</a> API supports passing an &lsquo;idempotency key&rsquo; with a request, and it guarantees that, in a 24 hour window, it won&rsquo;t reprocess two API calls that share the same key.</p>

<h3>Nice-to-have traits</h3>

<h4>Consumer-side failure recovery</h4>

<p>I was very close to including this trait within the must-haves group, but decided to be lenient. Now that we understand autonomy to be a key attribute for reactive microservices, it follows, in my opinion, that consumers must be responsible for recovering from their own failures without burdening upstream sources of events. I&rsquo;ve worked with message oriented systems where a producer of events is relied upon to re-dispatch messages in the event a downstream consumer has got itself in a mess. It strikes me that such an approach is not compliant with the autonomy objective &ndash; if a consumer is dependent on a producer going beyond its operational responsibilities to help it recover from failure, the autonomy of that consumer is called in to question.</p>

<p>This trait drives an alternative way of thinking from more traditional forms of middleware and/or integration patterns. In the third part of this series of posts, I&rsquo;ll look at how distributed commit log technologies (such as Apache Kafka and Amazon Kinesis) have a considerable advantage over traditional MQ and pub/sub technologies in regard to this nice-to-have integration trait. It boils down to inversion of control, whereby the responsibility for tracking a consumer&rsquo;s progress through a stream of events becomes the responsibility of the consumer rather than a central messaging broker.</p>

<h4>Decoupled in space</h4>

<p>In the must-haves section, I covered the trait of integration being decoupled in time. Going a stage further, you can aim for services to be decoupled in space as well. Anyone who has worked with a service-oriented architecture, especially where synchronous integration between services is the norm, will be familiar with the challenge of service addressability. Dealing with the overhead of managing configuration for many service endpoints can be quite a burden.</p>

<p>If we&rsquo;re able to remove this overhead in some way, thus achieving significant location transparency, it can further simplify our service integration challenges. Using middleware technology is a great way of achieving this. Decoupling in space is also possible without middleware &ndash; contemporary service discovery/locator patterns do facilitate this to some extent &ndash; and I&rsquo;ll weigh up the two approaches in the third and final post of this series.</p>

<h4>Parallelism</h4>

<p>In an ideal world, we&rsquo;d want the ability the parallelise the processing capabilities of a specific consumer by starting multiple instances. A common pattern when using messaging middleware is to have a single queue with multiple consumers each being sent messages in a round-robin fashion, with no consumer receiving the same message. This approach works fine in scenarios where processing messages in order is not important. However, as discussed in the must-haves section, we&rsquo;ll often encounter the need for a consumer to process a stream of events strictly in order, especially when applying service choreography based integration. As also discussed earlier, it&rsquo;s rarely the case that a consumer cares to receive every event in order, more likely it&rsquo;s important that events that are related in some way to each other are processed from a stream in the order they were generated (e.g. events emanating from a specific aggregate instance). With this in mind, it&rsquo;s a nice-to-have to find a way to parallelise consumers, whilst still ensuring events related to each other are processed in order. By doing this we get these primary benefits:</p>

<ol>
<li>We can improve the performance of our system through horizontal scaling, reducing the latency of eventual consistency.</li>
<li>It&rsquo;s easier to implement high availability of consumers rather than have single points of failure.</li>
<li>We can avoid a consumer use case being completely blocked when encountering a repeated error in processing a single event. If we&rsquo;re able to parallelise in some way, we can at least have that consumer use case continue processing some events (as long as they aren&rsquo;t related to the stubborn one) rather than stopping processing altogether.</li>
</ol>


<p>In the third part of this series of posts, I&rsquo;ll look at the technology options available to us that enable both guaranteed in-order processing <em>and</em> parallel consumers.</p>

<h2>Wrapping up</h2>

<p>Phew, that&rsquo;s the end of a long post! I&rsquo;ve covered both the must-have traits and the nice-to-have traits of microservices integration implementations that are supportive of service choreography. In the third and final post of this series, I&rsquo;ll at last get round to looking at specific technologies and techniques that enable us to satisfy these traits. Stay tuned!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The art of microservices integration using service choreography]]></title>
    <link href="http://DrewEaster.github.io/blog/2016/05/08/the-art-of-microservices-integration-using-service-choreography/"/>
    <updated>2016-05-08T22:10:00+01:00</updated>
    <id>http://DrewEaster.github.io/blog/2016/05/08/the-art-of-microservices-integration-using-service-choreography</id>
    <content type="html"><![CDATA[<p>This is the first post in a three part series looking at the topic of microservice integration. In this first instalment, I&rsquo;ll be focusing mainly on the theory side of event-driven service choreography. In the second post, I&rsquo;ll cover the implementation traits required to satisfy the theory discussed in this first post, and, in final post, I&rsquo;ll be assessing the support available for those traits in well known implementation technologies. So, let&rsquo;s get on with part one!</p>

<h2>Looking back</h2>

<p>One of the biggest shortcomings of traditional SOA is/was the tendency to break up a highly-coupled monolith into a series of smaller services with the same level of coupling that was previously internal to the monolith. The likely result being a distributed monolith with all the same problems you had before, but now with an additional operational burden &ndash; you end up in a worse position than if you&rsquo;d just stuck with the monolith!</p>

<p>It&rsquo;s this learning that I believe was the main catalyst for the development of the microservices architecture pattern (SOA 2.0?). In hindsight it seems pretty obvious; if you can&rsquo;t run a service in isolation, with significant levels of autonomy, it&rsquo;s pretty hard to justify why a piece of functionality is better in a separate service than simply internal to a monolith. It&rsquo;s not like there aren&rsquo;t some potentially good reasons why people would choose to do old style SOA, it&rsquo;s just you find those good reasons are outweighed by the negatives most of the time.</p>

<h2>Looking forward</h2>

<p>So, enter the world of microservices architecture, and the promise of isolation, autonomy, single-responsibility, encapsulated persistence etc. But, what exactly allows one to achieve such isolation and autonomy?</p>

<p>In this post, I&rsquo;m going to focus on how getting service integration right is a fundamental part of what enables services to be isolated, and act autonomously. I believe having a thorough understanding of the principles of good service integration can train your mind into grasping the importance of good service separation. As a little bonus, I&rsquo;ll close this post by looking at some considerations for good service separation.</p>

<h2>Service orchestration vs service choreography</h2>

<p>In a classic distributed monolith scenario as described above, the prevalent integration technique is likely to involve service <em>orchestration</em>. This is where backend services typically have a high-level of synchronous coupling &ndash; i.e. a service is reliant on other services to be operational and working, within a single request/response cycle, in order for it to carry out its own responsibilities. Such real-time dependencies prevent a service from acting autonomously &ndash; any failures in its dependencies will inevitably cascade, preventing the service from fulfilling its own responsibility. Here&rsquo;s a visualisation of service orchestration in action:</p>

<p><a href="/images/service_orchestration.png"><img class="center" src="/images/service_orchestration.png"></a></p>

<p>In this example, service A is dependent on both service B and service C when handling its own inbound HTTP calls. Service A fetches state X (from service B) state Y (from service C), aggregating them with some of its own state, Z, to finally yield an HTTP response to its callers. Failures in either B or C will prevent A from fully fulfilling its responsibilities &ndash; it may be able to degrade gracefully but the ability to do so really depends on context.</p>

<p>Contrast this scenario with service <em>choreography</em> instead. In a system designed to embrace choreography, services will typically avoid synchronous coupling &ndash; i.e. any integration between services does not apply during the usual request/response cycle. In such cases, a service can fulfill its responsibilities within the request/response cycle without the need to make further calls to other services (with the exception of persistence backends owned solely by the service).</p>

<p>The classic way to achieve this is via embracing an event-driven (message passing) approach to integration. That is, any state that a service requires from services external to it, is projected internally from event streams published by those external services. Such internal projections will be managed and updated completely asynchronously (outside of the request/response cycle), and will be eventually consistent. In the true spirit of microservices, the service entirely encapsulates all the persistent state it requires in order to fulfill its responsibilities, achieving true isolation and autonomy.</p>

<p>Let&rsquo;s refactor the previous diagram to reflect choreography instead of orchestration:</p>

<p><a href="/images/service_choreography.png"><img class="center" src="/images/service_choreography.png"></a></p>

<p>In this updated approach, service A receives events from streams published by service B and service C. Service A processes events in an eventually consistent manner, and persists locally only what it needs of state X and Y, alongside its own state, Z. When handling an incoming request, service A does not need to communicate with service B or service C.</p>

<h2>Clarifying asynchronous integration in service choreography</h2>

<p>I feel there&rsquo;s some confusion where people refer to asynchronous communication, especially in the field of microservices integration. It&rsquo;s worth some time to clarify what&rsquo;s meant in the context of service choreography.</p>

<p>What it&rsquo;s not:</p>

<ul>
<li><p><strong>Non-blocking I/O</strong> &ndash; I&rsquo;m an advocate of asynchronous, non-blocking I/O as part of building more efficient, resilient and scalable services that interact in some way with external I/O. However, in the context of service choreography, this is certainly not what we mean by asynchronous integration. Non-blocking I/O could still be used within the request/response cycle for orchestration use cases, and, whilst it has its advantages in one sense, certainly doesn&rsquo;t, on its own, buy any architectural benefits of isolation and autonomy.</p></li>
<li><p><strong>Classic MQ Request/Reply</strong> &ndash; It&rsquo;s possible using classic MQ technology (e.g. JMS, AMQP) to achieve asynchronous request/reply behaviour. You could pop a message on a queue, and wait for a response on some temporary reply queue. There&rsquo;s certainly some added decoupling in that the caller needn&rsquo;t know exactly who will reply, but, like with non-blocking I/O, if this is being done as part of a service handling an incoming request, then, despite the communication with the MQ itself being asynchronous in nature, the service is still not acting autonomously. If a consumer responsible for replying is down, and the call must then timeout, it&rsquo;s ultimately no different to an HTTP endpoint being unavailable or failing.</p></li>
</ul>


<p>So, to clarify things then. When we&rsquo;re talking about services being integrated asynchronously as part of service choreography, we&rsquo;re referring to a service being <em>free from the need to rely on its dependencies during the request/response lifecycle</em>.</p>

<h2>End-to-end autonomy</h2>

<p>Where I&rsquo;ve covered isolation and autonomy in this post, I&rsquo;ve been referring to <em>runtime</em> autonomy. It&rsquo;s worth noting that a strong motivation for isolating services is the autonomy they additionally afford throughout the entire engineering process. The event-driven integration nature of service choreography sits very naturally with the desire to assign clear ownership to specific teams, enabling them to develop, build, test and release independently. Whilst there are techniques to support these things alongside service orchestration, I find it much easier to reason about isolation and independence when service dependencies are largely confined to the background.</p>

<p>When considering service/API level tests, embracing eventually consistent, event-driven integration allows you to focus on data fixtures as opposed to service virtualisation. There&rsquo;s something inherently more simple &ndash; in my mind &ndash; about placing a system into a desired state via a simulated event stream, rather than having to worry about mocking/stubbing/virtualising some external service endpoint(s).</p>

<h2>Added complexity?</h2>

<p>Service choreography, without doubt, introduces a level of technical complexity beyond orchestration. Rather than the apparent simplicity of making calls to dependencies in real-time, you need to both produce events yourself and consume events from others; it requires a fundamental shift in the way you build software. It exposes you to such challenges as guaranteeing at-least-once-delivery/processing of events, handling out of order events, ensuring idempotency in event consumers, factoring in eventual consistency in the UI etc.</p>

<p>Like with anything in software engineering, it&rsquo;s all about tradeoffs. There&rsquo;s no silver bullet, and you have to make a call based on your own unique circumstances. There will always be times where the simplicity of orchestration will trump its limitations on autonomy. Making such calls is why experience matters and why there will always be room for judgement in engineering.</p>

<p>For example, a team may decide that it&rsquo;s ok for services acting as companions to some primary service &ndash; and so invisible outside the context of the service&rsquo;s public contract &ndash; to use orchestration, reserving choreography for integrating with services owned by other teams. In this scenario, the team would still benefit from the greater independence they&rsquo;ll have from other teams, whilst losing some runtime autonomy internally.</p>

<p>Additionally, there are times when integrating with third-party services (outside your organisation) will necessitate a degree of orchestration given limitations in the third-party API contracts.</p>

<p>As a general system wide architectural constraint, it&rsquo;s wise to be rigid about enforcing service choreography between services owned by different teams. This has the added benefit of really helping to drive home the importance of good service boundaries &ndash; if your design relies on orchestration between services owned by different teams, there&rsquo;s a good chance you&rsquo;ve not found sensible business-oriented boundaries between your services. A word of caution, though: where services are clearly aligned with business boundaries, choreography should be the preferred approach, even if the services are owned by the same team.</p>

<h2>Touching on boundaries</h2>

<p>Whilst service choreography enables autonomy, the elephant in the room is that a dependency is still a dependency, whether it be event-driven or not. If a service is required to consume from a large number of event streams, it&rsquo;s still adding overhead in terms of managing the dependencies over time.</p>

<p>One of the fundamental mistakes people make with microservices is to draw technical boundaries rather than boundaries of business capability/purpose. The use of the word &ldquo;micro&rdquo; is surely partly to blame, as it may appear to encourage highly granular service responsibilities. By breaking up a monolith into services of a highly technical nature, with little correlation to the business domain, you&rsquo;re inevitably going to introduce more dependencies, and accordingly more overhead. Too many dependencies of any variety is almost certainly a design smell, a sign of high coupling and low cohesion, when it&rsquo;s the exact opposite we&rsquo;re looking for. If you&rsquo;re stuck with lots of dependencies, it&rsquo;s a sure fire way of spotting that you&rsquo;ve drawn your boundaries wrong. If you&rsquo;ve managed to identify a genuine business capability, you&rsquo;ll be surprised at its fairly natural properties of isolation and independence.</p>

<p>Domain-Driven Design equips us with the toolset &ndash; and mindset &ndash; to identify business-oriented boundaries, and there&rsquo;s certainly reason to see a close relationship between microservice boundaries and Bounded Contexts as described in DDD. Whilst I don&rsquo;t consider there to be a direct 1:1 mapping in every circumstance (a good subject for another post), there are definitely some parallels to draw.</p>

<p>One way to go about reasoning about the need to introduce a dependency on an external event stream is to pedantically question the purpose of having that dependency in the first place. You may begin to find that you&rsquo;re tending to introduce such dependencies for the purpose of presenting data in a UI rather than for fulfilling specific business logic within your service boundary. In such cases, it can be preferable to rely on data aggregation/composition in the UI layer (where it&rsquo;s generally a little more acceptable/inevitable to rely on orchestration). When applying Domain-Driven Design to model business complexity, it&rsquo;s advisable to be ruthless about business purpose within any Bounded Context, and that means avoiding projecting state from external services if your service/domain doesn&rsquo;t <em>really</em> need it.</p>

<h2>Coming next</h2>

<p>That wraps up part one of this three part series. I&rsquo;ll be following up soon with part two within which I&rsquo;ll cover the implementation traits required to satisfy the theory discussed in this first post. Stay tuned!</p>
]]></content>
  </entry>
  
</feed>
